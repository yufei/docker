#
# If you want your data to persist, use a named volume and a volume driver that is multi-host aware, so that the data is accessible from any node. Or, set constraints on the service so that its tasks are deployed on a node that has the volume present.
#
# variable substitution, Your configuration options can contain environment variables. Compose uses the variable values from the shell environment ${variable}
# <key>: <option>: <value>

# duration: us, ms, s, m, h
# size: b, k, m, g, kb, mb, gb

# bionic support version 3.5
#version: "3.5"

version: "3"

services:

  app1:
    image: app1
    ports:
      - "container_port1"
      - "host_port:container_port"
      - target: container_port
        published: host_port
        protocol: tcp or udp
        mode: host or ingress
    networks:
      - network1
      - network2
        aliases:
          - alias1
          - alias2
    volumes:
      - volume1:/data
      - "host_path:container_path[:ro]"
      - type: volume or bind or tmpfs
        source: volume1 or /host_dir (not for tmpfs)
        target: /data
        read_only:
        bind:
          propagation:
        volume:
          nocopy: true
        tmpfs:
          size:
    stop_grace_period: 1m30s
    labels: # for all containers of service
      com.company.some_key: "some value"
    labels: # for all containers of service
      - "com.company.some_key=some value"
    deploy:
      mode: replicated or global
      replicas: 1
      placement:
        constraints: [node.role == manager]
        constraints:
          - node.role == manager
          - engine.labels.operatingsystem == ubuntu 14.04
        preferences:
          - spread: node.labels.zone
      labels: [key=value]
      labels: # for service
        com.company.some_key: "some_value"
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: continue or rollback or pause (default)
        monitor: (ns|us|ms|s|m|h) (default 0s)
        max_failure_ratio:
        order: stop-first (default) or start-first
      restart_policy:
        condition: on-failure, or none, or any (default)
        delay: 5s (default 0)
        max_attempts: 3 (default never giveup)
        window: 120s
      endpoint_mode: vip or dnsrr

    command:
    configs:
      - config1
      - config2
      - source: config3
        target: /config3
        uid: '100'
        gid: '100'
        mode: 0444
    secrets:
      - secret1
      - secret2
      - source: secret3
        target: secret3 (will be /run/secrets/secret3)
        uid: '100'
        gid: '100'
        mode: 0444

    resources:
      limits:
        cpus: '0.50'
        memory: 50M
      reservations:
        cpus: '0.25'
        memory: 20M
    dns:
    dns_search:
    tmpfs: # v3.6
      - type: tmpfs
        target: /app
        tmpfs:
          size: 1000
    entrypoint:
    env_file:
    environment:
    expose:
     - "port1" # only internal port
    extra_hosts:
      - "hostname:ipaddress"
    healthcheck:
      test:
      interval:
      timeout:
      retries:
      start_period:
      disable: true
    isolation:
    logging:
      driver:
      options:
    pid:
    stop_grace_period: (10s default)
    ulimits:
      nproc: 65535
      nofile:
        soft: 20000
        hard: 40000
    domainname:
    hostname:
    ipc:
    mac_address:
    privileged:
    read_only:
    shm_size:
    stdin_open:
    tty:
    user:
    working_dir:



networks:
  network1:
  network2:
    driver: bridge or overlay autoselect based on usage
    driver_opts:
    attachable: true
    external: true
    name: host or none
    labels:
    ipam:
      driver: default
      config:
        - subnet: 10.0.0.0/8
    internal: true # make the overlay network can not access externally
    external: true # conflict with other options
    external:
      name:

volumes:
  volume1:
  volume2:
    driver:
    driver_opts:
    external: true # conflict with other options
    external:
      name:
    name: name1
    labels:

configs: # /config
  config1:
    file: ./config1
    name:
  config2:
    external: true
    external:
      name:

secrets: # /run/secrets/<secret_name>
  secret1:
    file: ./secret1
    name: name1
  secret2:
    external: true
    external:
      name:
======================================================

version: "3"
services:

  redis:
    image: redis:alpine
    ports:
      - "6379"
    networks:
      - frontend
    deploy:
      replicas: 2
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure

  db:
    image: postgres:9.4
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - backend
    deploy:
      placement:
        constraints: [node.role == manager]

  vote:
    image: dockersamples/examplevotingapp_vote:before
    ports:
      - "5000:80"
    networks:
      - frontend
    depends_on:
      - redis
    deploy:
      replicas: 2
      update_config:
        parallelism: 2
      restart_policy:
        condition: on-failure

  result:
    image: dockersamples/examplevotingapp_result:before
    ports:
      - "5001:80"
    networks:
      - backend
    depends_on:
      - db
    deploy:
      replicas: 1
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure

  worker:
    image: dockersamples/examplevotingapp_worker
    networks:
      - frontend
      - backend
    deploy:
      mode: replicated
      replicas: 1
      labels: [APP=VOTING]
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 120s
      placement:
        constraints: [node.role == manager]

  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - "8080:8080"
    stop_grace_period: 1m30s
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints: [node.role == manager]

networks:
  frontend:
  backend:

volumes:
  db-data:
